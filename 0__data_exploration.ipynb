{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.datasets import load_digits, fetch_openml\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 -- Data Exploration & Preprocessing\n",
    "\n",
    "We will use three datasets throughout this tutorial:\n",
    "\n",
    "1. **Adult** – Tabular classification\n",
    "2. **Student Performance** – Tabular multi-target regression\n",
    "3. **Digits** – Image classification\n",
    "\n",
    "Let's explore each of them to understand their structure, features, and targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adult: Tabular classification\n",
    "\n",
    "Contains demographic information extracted from the 1994 US Census database. The task is to predict whether a person makes over 50K USD a year. \n",
    "\n",
    "Source: [Preprocessed (we use this here)](https://www.openml.org/search?type=data&sort=runs&id=179&status=active) | [Original](https://archive.ics.uci.edu/dataset/2/adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adult dataset\n",
    "data_adult = fetch_openml(\"adult\", version=2, as_frame=True)\n",
    "\n",
    "# split into features (X) and target (y)\n",
    "X_adult = data_adult.data\n",
    "y_adult = data_adult.target\n",
    "\n",
    "# for illustration purposes, let's work with only a subset of features\n",
    "feature_subset = ['age', 'education-num', 'race', 'sex', 'hours-per-week']\n",
    "X_adult = X_adult[feature_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "print(\"Shape:\", X_adult.shape)\n",
    "X_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "print(\"Shape:\", y_adult.shape)\n",
    "y_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X_adult.select_dtypes(include=\"category\").columns\n",
    "\n",
    "# Apply ordinal encoding\n",
    "encoder = OrdinalEncoder()\n",
    "X_adult = X_adult.copy()\n",
    "X_adult.loc[:, categorical_cols] = encoder.fit_transform(X_adult[categorical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #ffcc00; background-color: #fff8e1; padding: 10px; border-radius: 5px; color: black;\">\n",
    "<b>❓ Question:</b> How did one-hot encoding change the data?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Performance: Tabular multi-target regression\n",
    "\n",
    "The dataset contains student achievement data from two Portuguese secondary schools, covering demographics, social factors, and school-related attributes.\n",
    "Prediction targets are the grades G1, G2, and G3 of the first, second, and third year, respectively.\n",
    "\n",
    "Source: [UCI](https://archive.ics.uci.edu/dataset/320/student+performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student performance dataset\n",
    "data_students = fetch_ucirepo(id=320) \n",
    "\n",
    "# split into features and target\n",
    "X_students = data_students.data.features \n",
    "Y_students = data_students.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "print(\"Shape:\", X_students.shape)\n",
    "X_students.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets\n",
    "print(\"Shape:\", Y_students.shape)\n",
    "Y_students.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the grade range\n",
    "Y_students.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Encode categorical features\n",
    "X_students = pd.get_dummies(X_students)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digits: Image classification\n",
    "\n",
    "Images of hand-written digits from different people, here in low resolution (8x8) and grayscale (0-16). The dataset is widely used under the name MNIST.\n",
    "\n",
    "Source: [preprocessed (we use this here)](https://scikit-learn.org/stable/datasets/toy_dataset.html#digits-dataset) | [original](https://archive.ics.uci.edu/dataset/80/optical+recognition+of+handwritten+digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digits dataset\n",
    "data_digits = load_digits()\n",
    "\n",
    "# split into features and target\n",
    "X_digits = data_digits.data\n",
    "y_digits = data_digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\", X_digits.shape)\n",
    "print(\"Target classes:\", np.unique(y_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first few images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(data_digits.images[i], cmap=\"gray\")\n",
    "    ax.set_title(f\"Label: {y_digits[i]}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"Digits Dataset – Sample Images\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
