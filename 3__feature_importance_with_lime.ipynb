{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance with LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.datasets import load_digits, fetch_openml\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import label2rgb, gray2rgb, rgb2gray\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from lime.lime_image import LimeImageExplainer\n",
    "import cv2 as cv\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 -- Data Exploration & Preprocessing (copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digits dataset\n",
    "data_digits = load_digits()\n",
    "X_digits = data_digits.data\n",
    "y_digits = data_digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 -- Feature Importance with LIME\n",
    "\n",
    "LIME (Local Interpretable Model-agnostic Explanations) helps explain predictions of any classifier or regressor by approximating it **locally** with an interpretable model.\n",
    "\n",
    "Key Ideas:\n",
    "- LIME perturbs the input data around a specific instance and observes how the black-box model responds.\n",
    "- It then fits a simple, interpretable model (e.g., linear regression) to this neighborhood.\n",
    "- The coefficients of this simple model indicate which features influenced the prediction most for that instance.\n",
    "\n",
    "Why LIME?\n",
    "- Model-agnostic: works with any classifier or regressor.\n",
    "- Offers **local** explanations that are easy to understand.\n",
    "- Useful when you want to explain a single prediction rather than the model globally.\n",
    "\n",
    "LIME vs. SHAP:\n",
    "- Use LIME for quick, model-agnostic local explanations with simple interpretable output.\n",
    "- Use SHAP when you need consistent, theoretically grounded explanations—especially for tree-based models with TreeExplainer, where it's both fast and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1 -- LIME for Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digits (as before -- tabular arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluate a Random Forest model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits, random_state=42)\n",
    "\n",
    "# Model\n",
    "clf_digits = RandomForestClassifier(random_state=42)\n",
    "clf_digits.fit(X_train, y_train)\n",
    "\n",
    "# Baseline\n",
    "dummy_digits = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_digits.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "baseline_acc = accuracy_score(y_test, dummy_digits.predict(X_test))\n",
    "model_acc = accuracy_score(y_test, clf_digits.predict(X_test))\n",
    "\n",
    "print(f\"Baseline accuracy: {baseline_acc:.3f}\")\n",
    "print(f\"Random Forest accuracy: {model_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create explainer\n",
    "explainer = LimeTabularExplainer(X_train,\n",
    "                                  mode=\"classification\",\n",
    "                                  training_labels=y_train,\n",
    "                                  feature_names=[f\"pixel {i}\" for i in range(X_digits.shape[1])],\n",
    "                                  discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain a specific test sample\n",
    "i = 0  # sample index\n",
    "exp = explainer.explain_instance(X_test[i], clf_digits.predict_proba, num_features=10)\n",
    "exp.as_pyplot_figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 LIME Explanations Are Class-Specific\n",
    "\n",
    "By default, LIME explains the prediction for the **first class** only.\n",
    "\n",
    "If you want to generate explanations for other classes (e.g., the highest-predicted class), you must pass the `top_labels` parameter to `explain_instance`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose for how many classes (top _ classes) we need explanations\n",
    "exp = explainer.explain_instance(X_test[i], \n",
    "                                 clf_digits.predict_proba, \n",
    "                                 num_features=10, \n",
    "                                 top_labels=5) # here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which labels are now available \n",
    "## note that it's an ordered list; the first one is the top predicted class\n",
    "print(\"Available labels:\", [int(label) for label in exp.available_labels()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose for which class you want explanations\n",
    "exp.as_pyplot_figure(label=6)  # choose with \"label\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📦 **LIME on Images as Tabular Data**\n",
    ">\n",
    "We've treated the digits dataset as **tabular data**, where each feature corresponds to a pixel (flattened 8×8 image).  \n",
    "This allows us to use **LIME for tabular explanations**, but the results reference pixel indices rather than image locations.\n",
    "\n",
    "To visualize which parts of the image LIME focuses on, we need to **map the pixel-level importances back into image space** (i.e., reshape the 64-dimensional feature vector back into an 8×8 grid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get explanations, but include all features now\n",
    "exp = explainer.explain_instance(X_test[i], \n",
    "                                 clf_digits.predict_proba, \n",
    "                                 num_features=64, # here\n",
    "                                 top_labels=5) \n",
    "\n",
    "# Extract weights for the predicted class\n",
    "lime_dict = dict(exp.as_list(label=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem: the explanations look like that\n",
    "for item in list(lime_dict.items())[:3]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse pixel indices from strings like \"pixel 21 <= 0.00\"\n",
    "import re\n",
    "weights = np.zeros(64)\n",
    "\n",
    "for key, value in lime_dict.items():\n",
    "    match = re.search(r'pixel (\\d+)', key)\n",
    "    if match:\n",
    "        idx = int(match.group(1))\n",
    "        weights[idx] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a list of importances for each pixel:\n",
    "weights[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and plot\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(weights.reshape(8, 8), cmap=\"coolwarm\", vmin=-np.max(np.abs(weights)), vmax=np.max(np.abs(weights)))\n",
    "plt.title(\"LIME Pixel Importances (Class 6)\")\n",
    "plt.axis(\"off\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2 -- LIME for Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale globally from [0, 16] → [0, 255] because LIME wants that\n",
    "X_digits_rescaled = (X_digits / 16.0 * 255).astype(np.uint8)\n",
    "\n",
    "# Reshape the flattened digits to 8x8 images\n",
    "X_digits_img = X_digits_rescaled.reshape((-1, 8, 8))\n",
    "\n",
    "# Convert 8x8 grayscale images to RGB because LIME wants that\n",
    "X_digits_rgb = np.array([gray2rgb(img) for img in X_digits_img])\n",
    "\n",
    "print(X_digits_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model on flattened data (as required by sklearn)\n",
    "## You could also train a neural network with PyTorch etc.\n",
    "clf_digits = RandomForestClassifier(random_state=42)\n",
    "clf_digits.fit(X_digits_rescaled, y_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a wrapper around the RF predict_proba method: \n",
    "## convert RGB to grayscale and flatten, then use predict_proba\n",
    "def rf_wrapper(imgs):\n",
    "    grays = np.array([rgb2gray(img) for img in imgs])\n",
    "    return clf_digits.predict_proba(grays.reshape((grays.shape[0], -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one image to explain (2D image!)\n",
    "i = 0\n",
    "image = X_digits_img[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME explanation\n",
    "explainer = LimeImageExplainer(random_state=5)\n",
    "\n",
    "# Segmentation function\n",
    "## n_segments: controls the number of \"superpixels\" used to create areas\n",
    "##   of similar pixels in the image. LIME will explain the influence of these\n",
    "##   areas rather than stand-alone pixels (unless n_segments = the number of pixels)\n",
    "## compactness: balances color similarity and spatial similarity to form superpixels\n",
    "## start_label: superpixel labels will start from 0 (required by LIME)\n",
    "segments_fn = lambda img: slic(img, \n",
    "                               n_segments=16, \n",
    "                               compactness=0.5, \n",
    "                               start_label=0)\n",
    "\n",
    "# Obtaining explanations\n",
    "## hide_color: superpixels that are \"turned off\" during perturbation are filled\n",
    "##   with this value. These are irrelevant superpixels. Here: black\n",
    "## num_samples: LIME creates many perturbed versions of the image to fit a local\n",
    "##   surrogate model. Stability of results is expected to increase with higher\n",
    "##   values here.\n",
    "exp = explainer.explain_instance(\n",
    "    X_digits_rgb[i],              # image to explain\n",
    "    classifier_fn=rf_wrapper,     # model's prediction function\n",
    "    top_labels=1,                 # top _ classes will be explained\n",
    "    hide_color=0,                 \n",
    "    num_samples=1000,\n",
    "    segmentation_fn=segments_fn   # segmentation function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "temp, mask = exp.get_image_and_mask(\n",
    "    label=exp.top_labels[0],\n",
    "    positive_only=False,\n",
    "    num_features=5,\n",
    "    hide_rest=False\n",
    ")\n",
    "plt.imshow(label2rgb(mask, temp, bg_label=0, alpha=0.6))\n",
    "plt.title(f\"LIME explanation for class {exp.top_labels[0]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🟡 Interpretation:</b> Understanding positive and negative contributions\n",
    "\n",
    "This LIME explanation highlights both types of evidence the model used to classify the digit as a <b>5</b>:\n",
    "\n",
    "- <b>Red regions</b>: positively contributed to the classification as a 5 — they support the prediction.\n",
    "- <b>Blue regions</b>: negatively contributed — their presence made the model less confident in class 5.\n",
    "- <b>Gray areas</b>: either neutral or not selected among the top 5 most influential regions.\n",
    "\n",
    "This dual-color view gives a more nuanced picture of how the model balances supporting and opposing evidence when making predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️ LIME is Stochastic — Results May Vary\n",
    "\n",
    "LIME generates explanations by fitting a local surrogate model to randomly perturbed versions of the input image.  \n",
    "Because this sampling is **random**, the resulting explanation can **change** across runs — even for the same input image and class.\n",
    "\n",
    "This is especially noticeable when:\n",
    "- The number of perturbation samples (`num_samples`) is low,\n",
    "- The underlying model has sharp decision boundaries,\n",
    "- Or the input is near a class boundary.\n",
    "\n",
    "✅ To make results reproducible, set `random_state`  \n",
    "✅ To increase stability, use more samples (e.g., 3000+)\n",
    "\n",
    "Below, we visualize five LIME runs for the same input and class, using different seeds:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "segments_fn = lambda img: slic(img, n_segments=32, compactness=0.5, start_label=0)\n",
    "\n",
    "for ax, seed in zip(axes, [5, 6, 7, 8, 9]):\n",
    "    explainer = LimeImageExplainer(random_state=seed) # different seeds here\n",
    "    explanation = explainer.explain_instance(\n",
    "        X_digits_rgb[i],\n",
    "        classifier_fn=rf_wrapper,\n",
    "        top_labels=1,\n",
    "        hide_color=0,\n",
    "        num_samples=1000,\n",
    "        segmentation_fn=segments_fn\n",
    "    )\n",
    "    temp, mask = explanation.get_image_and_mask(\n",
    "        label=explanation.top_labels[0],\n",
    "        positive_only=False,\n",
    "        num_features=5,\n",
    "        hide_rest=False\n",
    "    )\n",
    "    ax.imshow(label2rgb(mask, temp, bg_label=0, alpha=0.6))\n",
    "    ax.set_title(f\"Seed {seed}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.4 -- Your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #ffcc00; background-color: #fff8e1; padding: 10px; border-radius: 5px; color: black;\">\n",
    "<b>🧠 Task:</b> Investigate how LIME explanations change with different settings.\n",
    "</br>\n",
    "\n",
    "Try modifying the following:\n",
    "<ul>\n",
    "  <li><code>n_segments</code>: how finely the image is segmented (e.g., 8, 16, 32, 64)</li>\n",
    "  <li><code>compactness</code>: how regular or irregular the superpixel shapes are</li>\n",
    "  <li><code>num_features</code>: how many superpixels to highlight in the final explanation</li>\n",
    "  <li><code>hide_color</code>: what color to use for masked regions</li>\n",
    "  <li><code>num_samples</code>: number of perturbations LIME uses to fit its local model</li>\n",
    "</ul>\n",
    "\n",
    "Observe:\n",
    "<ul>\n",
    "  <li>How do the explanations differ across settings?</li>\n",
    "  <li>Are some explanations more plausible or stable than others?</li>\n",
    "  <li>Would you trust this explanation if you had to make a decision based on it?</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #ffcc00; background-color: #fff8e1; padding: 10px; border-radius: 5px; color: black;\">\n",
    "<b>🧠 Task (Optional):</b> Try LIME on a higher-resolution dataset with a pretrained neural network.\n",
    "</br><br>\n",
    "\n",
    "Suggestions:\n",
    "<ul>\n",
    "  <li>Load a pretrained <b>MobileNet</b> model using OpenCV's <code>dnn</code> module</li>\n",
    "  <li>Download sample images from the web (e.g., animals, objects)</li>\n",
    "  <li>Apply LIME to explain the top prediction</li>\n",
    "</ul>\n",
    "\n",
    "Does LIME still give intuitive explanations? What changes when you move from digits to natural images?\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download a pretrained model \n",
    "\n",
    "import urllib.request\n",
    "\n",
    "# URLs to prototxt and caffemodel\n",
    "prototxt_url = 'https://github.com/shicai/MobileNet-Caffe/raw/master/mobilenet_deploy.prototxt'\n",
    "caffemodel_url = 'https://github.com/shicai/MobileNet-Caffe/raw/master/mobilenet.caffemodel'\n",
    "\n",
    "# Download files\n",
    "urllib.request.urlretrieve(prototxt_url, 'mobilenet_deploy.prototxt')\n",
    "urllib.request.urlretrieve(caffemodel_url, 'mobilenet.caffemodel')\n",
    "\n",
    "# Load the model\n",
    "net = cv.dnn.readNetFromCaffe(\"mobilenet_deploy.prototxt\", \n",
    "                              \"mobilenet.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a couple of images to play with (or use your own)\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "# URLs of a few example images from ImageNet (raw images)\n",
    "img_urls = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/2/26/YellowLabradorLooking_new.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/3/3a/Cat03.jpg\"\n",
    "]\n",
    "\n",
    "# For loading images from URL\n",
    "def preprocess_from_url(url):\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image_data = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    img = cv.imdecode(image_data, cv.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "# For LIME's internal perturbed images\n",
    "def preprocess_image(img):\n",
    "    return cv.dnn.blobFromImage(\n",
    "        img, scalefactor=1.0/127.5, size=(224, 224),\n",
    "        mean=(127.5, 127.5, 127.5), swapRB=True, crop=False\n",
    "    )\n",
    "\n",
    "# Test images for you:\n",
    "img1 = preprocess_from_url(img_urls[0])\n",
    "img2 = preprocess_from_url(img_urls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier wrapper for LIME\n",
    "def mobilenet_wrapper(imgs):\n",
    "    outputs = []\n",
    "    for img in imgs:\n",
    "        blob = preprocess_image(img)\n",
    "        net.setInput(blob)\n",
    "        out = net.forward()\n",
    "        outputs.append(out.flatten())\n",
    "    return np.vstack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME explainer and segmentation function\n",
    "explainer = LimeImageExplainer(random_state=42)\n",
    "segments_fn = lambda img: slic(img, n_segments=200, compactness=1, start_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain one of our images\n",
    "explanation = explainer.explain_instance(img2, \n",
    "                                         classifier_fn=mobilenet_wrapper,\n",
    "                                         top_labels=1,\n",
    "                                         hide_color=0,\n",
    "                                         num_samples=1000,\n",
    "                                         segmentation_fn=segments_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(label=explanation.top_labels[0],\n",
    "                                            positive_only=True,\n",
    "                                            num_features=1, # explore this\n",
    "                                            hide_rest=False)\n",
    "\n",
    "plt.imshow(label2rgb(mask, temp, bg_label=0, alpha=0.6))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 Insight:\n",
    "\n",
    "One of the key advantages of <b>LIME</b> is that it is <b>model-agnostic</b> — it doesn't need to know anything about the internal structure of the model you're explaining.\n",
    "\n",
    "In fact, in our example with MobileNet, <b>LIME has no idea</b> whether we're using a neural network, a random forest, or any other model. It simply queries the model via <code>predict_proba()</code> and builds a local approximation.\n",
    "\n",
    "This makes LIME flexible and powerful — it can work with:\n",
    "<ul>\n",
    "  <li>Any black-box model</li>\n",
    "  <li>High-dimensional feature spaces (e.g., images with thousands of pixels)</li>\n",
    "  <li>Both classification and regression problems</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #007acc; background-color: #e6f2ff; padding: 10px; border-radius: 5px; color: black;\">\n",
    "<b>ℹ️ Want to explore more?</b><br>\n",
    "Check out <a href=\"https://github.com/marcotcr/lime?tab=readme-ov-file\" target=\"_blank\">the LIME documentation</a> -- it contains lots of tutorials for different data types.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
